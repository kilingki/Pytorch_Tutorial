{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_RNN_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOv5PqIoQRt+vRCkCVrlybu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "60p-vteE04M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "RNN의 일종인 GRU를 이용, IMDB Dataset으로 문장 감정 분석을 해봅니다.\n",
        "텍스트 형태의 Dataset인 IMDB Dataset은 50,000건의 영화 리뷰로 이루어져 있습니다.\n",
        "각 리뷰는 다수의 영어 문장들로 이루어져 있으며, 평점이 7점 이상의 긍정적인 영화 리뷰는 2로, \n",
        "평점이 4점 이하인 부정적인 영화 리뷰는 1로 레이블링 되어 있습니다. \n",
        "영화 리뷰 텍스트를 RNN 에 입력시켜 영화평의 전체 내용을 압축하고, \n",
        "이렇게 압축된 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 만드는 것이 이번 프로젝트의 목표입니다.\n",
        "'''\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data, datasets\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40tVrfebeCBK",
        "colab_type": "code",
        "outputId": "f14cd8a4-c8e6-4a42-ab3d-9fc62fbdb376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 본인의 구글 드라이브 → 지금 실행중인 코드\n",
        "\n",
        "# google.colab.drive : 구글 드라이브에서 파일을 가져오기 위한 코드를 담고 있다.\n",
        "from google.colab import drive\n",
        "\n",
        "# 본인의 구글 드라이브를 '/gdrive' 라는 경로로 하여 쓸 수 있다.\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgJ0MFWl8WBF",
        "colab_type": "code",
        "outputId": "07b17f65-521a-40a4-bb98-151c3899a777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Hyperparameter\n",
        "batch_size = 64\n",
        "lr = 0.001\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE7K4Wds8WJl",
        "colab_type": "code",
        "outputId": "32502b07-8c37-4ba8-e937-d7348dc1312f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 데이터 로딩하기\n",
        "print(\"데이터 로딩중...\")\n",
        "\n",
        "text = data.Field(sequential=True, # 시계열 데이터임을 알림\n",
        "                  batch_first=True, # (Batch_size, ?, ?)\n",
        "                  lower=True) # 모든 대문자 -> 소문자 변환\n",
        "\n",
        "label = data.Field(sequential=False, \n",
        "                   batch_first=True)\n",
        "\n",
        "# IMDB를 text / label 로 나누어 위에 정의한 Field에 각각 나눠 담는다\n",
        "trainset, testset = datasets.IMDB.splits(text, label)\n",
        "\n",
        "# Vocabulary 형성\n",
        "text.build_vocab(trainset,\n",
        "                 min_freq=5)  # 5번 이상 등장한 단어만 token화하여 vocabulary에 추가\n",
        "\n",
        "label.build_vocab(trainset)\n",
        "\n",
        "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "\n",
        "# 학습 시 반복문 활용을 위한 Iterator 지정\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "                                  (trainset, valset, testset), \n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True, \n",
        "                                  repeat=False)\n",
        "# Output Shape\n",
        "n_classes = 2 # Positive / Negative\n",
        "\n",
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), len(text.vocab), n_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 로딩중...\n",
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub-a_RlKjNot",
        "colab_type": "code",
        "outputId": "e7ed6d22-f7a3-464e-a138-32c9a7368fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Training Set의 첫번째 Text 및 Label 시각화\n",
        "print(vars(trainset[0])['text'])\n",
        "print(vars(trainset[0])['label'])\n",
        "for i in range(10):\n",
        "  print(len(vars(trainset[i])['text']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['heart', 'pounding', 'erotic', 'drama', 'are', 'the', 'words', 'that', 'come', 'to', 'mind', 'when', 'i', 'think', 'of', '\"secret', 'games\".', 'it', 'becomes', 'more', 'erotic', 'as', 'the', 'film', 'goes', 'along', 'and', 'at', 'one', 'point', 'blew', 'me', 'away!', 'i', \"didn't\", 'expect', 'the', 'delightful', 'scene', 'i', 'was', 'about', 'to', 'encounter.', 'the', '\"call', 'girl\"', 'has', 'her', 'first', 'customer', 'and', 'what', 'a', 'customer!', 'one', 'of', 'the', 'most', 'erotic', 'lesbian', 'scenes', 'i', 'have', 'ever', 'seen.', 'the', 'husband', 'should', 'have', 'listened', 'to', 'his', 'wife', 'and', 'perhaps', 'she', \"wouldn't\", 'have', 'gone', 'on', 'this', 'erotic', 'journey.', 'it', 'turned', 'out', 'to', 'cost', 'them', 'in', 'the', 'end', 'but,', 'it', 'was', 'one', 'exciting', 'ride!', 'go', 'see', 'this', 'movie!!!']\n",
            "pos\n",
            "103\n",
            "129\n",
            "230\n",
            "181\n",
            "148\n",
            "144\n",
            "132\n",
            "212\n",
            "160\n",
            "734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guCH2YdX8WHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 정의\n",
        "class BasicGRU(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "    super(BasicGRU, self).__init__()\n",
        "    print(\"Building Basic GRU model...\")\n",
        "    self.n_layers = n_layers # Stacked RNN의 층 수 결정\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim) # Vocab Embedding\n",
        "    self.hidden_dim = hidden_dim # Dimension of Hidden state of RNN\n",
        "    self.dropout = nn.Dropout(dropout_p) # Dropout\n",
        "\n",
        "    # GRU Model 정의\n",
        "    self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                      num_layers=self.n_layers,\n",
        "                      batch_first=True)\n",
        "    # 출력층 MLP\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "  # RNN 내부 State 초기화\n",
        "  def _init_state(self, batch_size=1):\n",
        "    # Model의 parameter의 data를 weight로 뽑아온다\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    # 새로운 Tensor 생성 후 0으로 초기화\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
        "\n",
        "  # Feed-Fowarding 함수\n",
        "  def forward(self, x):\n",
        "    x = self.embed(x) # Vocab -> Vector\n",
        "    h_0 = self._init_state(batch_size=x.size(0))\n",
        "        \n",
        "    # GRU는 x(모델 출력), _ (hidden/cell state) 반환\n",
        "    x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "\n",
        "    # 출력 중 시간 상 맨 마지막 출력만 따온다\n",
        "    h_t = x[:,-1,:]\n",
        "\n",
        "    # Dropout 적용\n",
        "    self.dropout(h_t)\n",
        "\n",
        "    # 출력의 MLP층 적용, 출력 차원(2)로 맞춰준다\n",
        "    pred = self.out(h_t)  # [b, h] -> [b, o]\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGCm4jHi8WE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습 함수 정의\n",
        "def train(model, optimizer, train_iter):\n",
        "    model.train() # Dropout 및 Gradient 계산 활성화\n",
        "\n",
        "    # Iterator를 이용한 반복문\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        # Batch 별로 Text / Label 각각을 학습 장치(GPU)로 보낸다\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "\n",
        "        # Label 값을 0과 1로 변환 (IMDB의 Label은 1 or 2 로 되어있습니다)\n",
        "        # sub_ : sub() 함수의 In-place (자신에게 적용되는) version\n",
        "        # sub(x) : x 값을 self에서 빼줍니다.\n",
        "        y.data.sub_(1)\n",
        "\n",
        "        optimizer.zero_grad() # Gradient 초기화\n",
        "        logit = model(x) # Feed-Fowarding\n",
        "\n",
        "        # Label과 Model 출력의 CEE 계산\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "\n",
        "        loss.backward() # Gradient 계산\n",
        "        optimizer.step() # Parameter Update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc-2_cqY8fWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 평가 함수 정의\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval() # Dropout 및  Gradient 계산 중지\n",
        "\n",
        "    # 덧셈 누적을 위한 변수\n",
        "    # corrects : 맞은 숫자 누적\n",
        "    # total_loss : Loss 값 누적\n",
        "    corrects, total_loss = 0, 0\n",
        "\n",
        "    # Iterator를 통한 Validation을 위한 반복문 실행\n",
        "    for batch in val_iter:\n",
        "        # 위와 동일\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        out = model(x)\n",
        "\n",
        "        # reduction='sum' : 출력이 모두 더해져 하나의 값으로 나온다\n",
        "        loss = F.cross_entropy(out, y, reduction='sum')\n",
        "        \n",
        "        total_loss += loss.item() # Loss 누적\n",
        "\n",
        "        # out : tensor.size = ([batch_size, 2])\n",
        "        # out.max(1) : out.max(1)[0] : 2개 값 중 최댓값의 Index가 1인 경우의 값 리스트\n",
        "        #                out.max(1)[1] : 최댓값의 Index가 1인 경우 1, 아닌 경우 0\n",
        "        # (out.max(1)[1].data == y.data) : 해당 Index의 Label과 Model 출력이 같으면 True, 다르면 False : ([batch_size,])\n",
        "        # (out.max(1)[1].data == y.data).sum() : True 인 값의 갯수\n",
        "        corrects += (out.max(1)[1].data == y.data).sum() # 정답 수 누적\n",
        "        \n",
        "    # Loss 정규화\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "\n",
        "    # Accuracy 계산\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE34V_gPr7yq",
        "colab_type": "code",
        "outputId": "f6b6fd78-f698-4479-9c8a-909ba878b22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "a = torch.ones((10, 2))\n",
        "for i in a:\n",
        "  i[0] = 0\n",
        "\n",
        "b = torch.ones((1, 10))\n",
        "print(b, '\\n')\n",
        "\n",
        "print(a, '\\n')\n",
        "print(a.max(1), '\\n')\n",
        "print(a.max(1)[1])\n",
        "print(a.max(1)[1].data)\n",
        "print(a.max(1)[1].data == b.data)\n",
        "print((a.max(1)[1].data == b.data).sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]) \n",
            "\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.]]) \n",
            "\n",
            "torch.return_types.max(\n",
            "values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
            "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])) \n",
            "\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([[True, True, True, True, True, True, True, True, True, True]])\n",
            "tensor(10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnfWCp6K8kXZ",
        "colab_type": "code",
        "outputId": "5f8840b3-29f5-4647-98a4-5dedf53c4a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Model 객체화\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Basic GRU model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDAquB5L8faR",
        "colab_type": "code",
        "outputId": "82cc672c-4bc0-4619-89d5-28529fc8ad04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "best_val_loss = None\n",
        "\n",
        "# Epoch 동안 학습 진행\n",
        "for e in range(1, epochs+1):\n",
        "    train(model, optimizer, train_iter) # 학습 진행\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter) # 검증 진행\n",
        "\n",
        "    # 진행 결과 출력\n",
        "    print(\"[Epoch %d] Val_Loss :%5.2f | Val_Acc :%5.2f\" % (e, val_loss, val_accuracy))\n",
        "    \n",
        "    # Validation Loss가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        torch.save(model.state_dict(), '/gdrive/My Drive/RNN_IMDB.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1] Val_Loss : 0.69 | Val_Acc :50.20\n",
            "[Epoch 2] Val_Loss : 0.69 | Val_Acc :51.86\n",
            "[Epoch 3] Val_Loss : 0.67 | Val_Acc :59.46\n",
            "[Epoch 4] Val_Loss : 0.35 | Val_Acc :85.60\n",
            "[Epoch 5] Val_Loss : 0.32 | Val_Acc :86.90\n",
            "[Epoch 6] Val_Loss : 0.35 | Val_Acc :87.18\n",
            "[Epoch 7] Val_Loss : 0.39 | Val_Acc :87.82\n",
            "[Epoch 8] Val_Loss : 0.47 | Val_Acc :86.16\n",
            "[Epoch 9] Val_Loss : 0.48 | Val_Acc :87.02\n",
            "[Epoch 10] Val_Loss : 0.51 | Val_Acc :86.70\n",
            "[Epoch 11] Val_Loss : 0.56 | Val_Acc :86.94\n",
            "[Epoch 12] Val_Loss : 0.51 | Val_Acc :87.24\n",
            "[Epoch 13] Val_Loss : 0.54 | Val_Acc :86.68\n",
            "[Epoch 14] Val_Loss : 0.56 | Val_Acc :87.42\n",
            "[Epoch 15] Val_Loss : 0.59 | Val_Acc :87.62\n",
            "[Epoch 16] Val_Loss : 0.63 | Val_Acc :87.44\n",
            "[Epoch 17] Val_Loss : 0.65 | Val_Acc :87.52\n",
            "[Epoch 18] Val_Loss : 0.68 | Val_Acc :87.52\n",
            "[Epoch 19] Val_Loss : 0.70 | Val_Acc :87.42\n",
            "[Epoch 20] Val_Loss : 0.72 | Val_Acc :87.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwiR-hoikv7k",
        "colab_type": "code",
        "outputId": "0ae3d3f8-e1c0-48cc-a991-a4c929f9c57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/RNN_IMDB.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))\n",
        "\n",
        "# 시각화\n",
        "model.eval() # Dropout 및 Gradient 계산 중지\n",
        "\n",
        "Class = ['Negative', 'Positive']\n",
        "Token_to_String = [] # Token을 문자열로 바꾼 뒤 담을 리스트\n",
        "\n",
        "# Iterator를 통한 Test를 위한 반복문 한번만 실행\n",
        "for batch in test_iter:\n",
        "\n",
        "  # 위와 동일\n",
        "  x, y = batch.text.to(device), batch.label.to(device)\n",
        "  y.data.sub_(1)\n",
        "  out = model(x)\n",
        "\n",
        "  # reduction='sum' : 출력이 모두 더해져 하나의 값으로 나온다\n",
        "  loss = F.cross_entropy(out, y, reduction='sum')\n",
        "\n",
        "  # out.max(1)[1] (Tensor, GPU) -> .data (Gradient 계산 및 1인 차원 제거, Tensor, GPU) -> (Tensor, CPU) -> (ndarray, CPU)\n",
        "  pred_batch = out.max(1)[1].data.cpu().numpy() # Batch 단위 Model 출력 값\n",
        "  ans_batch = y.data.cpu().numpy() # Batch 단위 Label 값\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    tok_to_str = [] # 문장 단위로 담을 리스트\n",
        "    for token in x[i]: \n",
        "      # x가 갖는 Token 각각을 원래 단어로 바꿔준다\n",
        "      tok_to_str.append(text.vocab.itos[token])\n",
        "\n",
        "    # 문장을 전체 리스트에 추가\n",
        "    Token_to_String.append(tok_to_str) \n",
        "\n",
        "  # 반복문 탈출 : 반복문을 딱 한번 실행\n",
        "  break \n",
        "\n",
        "for i in range(batch_size):\n",
        "    print(Token_to_String[i])\n",
        "    print('Answer :', Class[ans_batch[i]])\n",
        "    print('Prediction :', Class[pred_batch[i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 오차:  0.33 | 테스트 정확도: 86.32\n",
            "[\"i've\", 'seen', 'soap', 'operas', 'more', 'intelligent', 'than', 'this', 'movie.', 'bad', 'characters,', 'bad', 'story', 'and', 'bad', 'acting.', 'it', 'would', 'be', 'a', 'love', 'story', 'between', 'a', 'man', 'and', 'a', 'mermaid.', 'really', 'awful.']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['this', 'movie', 'is', 'based', 'on', 'the', 'novel', 'island', 'of', 'dr.', 'moreau', 'by', 'h.g.', '<unk>', \"it's\", 'a', 'fairly', 'good', 'one', 'too,', \"it's\", 'at', 'least', 'better', 'than', 'the', 'version', 'by', 'john', '<unk>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['albert', 'pyun', 'delivers', 'a', 'very', 'good', '<unk>', 'about', 'a', 'junkie', 'who', 'tries', 'to', 'rip-off', 'a', 'big', '<unk>', 'a', 'lot', 'of', 'style', 'and', 'many', 'very', 'cool', 'actors.', 'burt', '<unk>', 'is', 'excellent.']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['complete', 'entertainment!', 'although', 'there', 'are', 'many', 'strange', 'things', 'in', 'the', 'movie', 'that', 'the', 'fairy', 'tale', 'itself', \"doesn't\", 'have', 'them', 'including', 'the', 'autumn', 'characters', '<unk>', 'and', 'daughter)', 'the', 'general', 'concept', 'rocks.']\n",
            "Answer : Positive\n",
            "Prediction : Negative\n",
            "['this', 'movie', 'turned', 'out', 'to', 'be', 'better', 'than', 'i', 'had', 'expected', 'it', 'to', 'be.', 'some', 'parts', 'were', 'pretty', 'funny.', 'it', 'was', 'nice', 'to', 'have', 'a', 'movie', 'with', 'a', 'new', 'plot.']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['a', 'really', 'realistic,', 'sensible', 'movie', 'by', 'ramgopal', 'verma', '.', 'no', 'stupidity', 'like', 'songs', 'as', 'in', 'other', 'hindi', 'movies.', 'class', 'acting', 'by', 'nana', '<unk>', '<br', '/><br', '/>much', 'similarities', 'to', 'real', '<unk>']\n",
            "Answer : Positive\n",
            "Prediction : Negative\n",
            "['the', 'one-liners', 'fly', 'so', 'fast', 'in', 'this', 'movie', 'that', 'you', 'can', 'watch', 'it', 'over', 'and', 'over', 'and', 'still', 'catch', 'new', 'ones.', 'by', 'far', 'one', 'of', 'the', 'best', 'of', 'this', 'genre.']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['at', 'least', 'the', 'jingle', 'by', 'tim', '<unk>', 'was', '<unk>', 'roberts', 'is', 'the', 'his', 'usual', 'inept', 'self.', 'characters', 'are', 'inconsistent,', 'dull,', '<unk>', 'roberts', 'changes', 'his', 'accent', 'even', 'within', 'one', 'line.', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['you', 'may', 'like', 'tim', \"burton's\", '<unk>', 'but', 'not', 'in', 'a', '<unk>', 'show', 'off', 'lasting', '8', 'minutes.', 'it', 'demonstrates', 'good', 'technical', 'points', 'without', 'real', 'creativity', 'or', 'some', 'established', 'narrative', 'pace.', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['at', 'one', 'point', 'in', 'this', 'waste', 'of', 'celluloid,', 'charles', 'dance', 'as', 'some', 'sort', 'of', '<unk>', 'cyborg', 'bad', 'guy', 'says', '\"if', 'i', 'had', 'an', '<unk>', \"i'd\", 'soil', '<unk>', '/><br', '<unk>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['the', 'buddy', 'holly', 'story', 'is', 'a', 'great', 'biography', 'with', 'a', 'super', 'performance', 'from', 'gary', '<unk>', 'busey', 'did', 'his', 'own', 'singing', 'for', 'this', 'film', 'and', 'he', 'does', 'a', 'great', 'job.', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "[\"it's\", 'not', 'citizen', 'kane,', 'but', 'it', 'does', 'deliver.', '<unk>', 'and', 'lots', 'of', 'it.<br', '/><br', '<unk>', 'acted', 'and', 'directed,', 'poorly', 'scripted.', 'who', 'cares?', 'i', \"didn't\", 'watch', 'it', 'for', 'the', 'dialog.', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Negative\n",
            "['this', 'is', 'a', 'very', 'cool', 'movie.', 'the', 'ending', 'of', 'the', 'movie', 'is', 'a', 'bit', 'more', 'defined', 'than', 'the', \"play's\", 'ending,', 'but', 'either', 'way', 'it', 'is', 'still', 'a', 'good', 'movie.', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['i', 'see', 'it', 'when', 'i', 'was', '12', 'year', 'old', 'and', 'i', 'dream', 'to', 'see', 'it', 'again', '!<br', '/><br', '/>what', 'marvelous', 'sammy', 'davis', 'jr', 'singing', '\"it', \"ain't\", 'necessarily', 'so', '<unk>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['1st', 'watched', '<unk>', '-', '<unk>', '<unk>', 'very', 'thought', 'provoking', 'and', 'very', 'well', 'done', 'movie', 'on', 'the', 'subject', 'of', 'the', 'death', 'penalty.', 'deserved', 'more', 'recognition', 'and', 'publicity', 'than', 'it', 'received.', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['wonderful', 'movie.', 'adult', 'content.', 'lots', 'of', 'erotic', 'scenes', 'plus', 'excellent', 'music', 'and', 'dance', 'scenes.', 'my', 'wife', 'and', 'i', 'absolutely', 'loved', 'this', 'movie', 'and', 'wish', \"they'd\", 'make', 'more', 'like', 'it.', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['a', 'real', 'hoot,', '<unk>', 'sidney', '<unk>', 'character', 'is', 'so', 'sweet', 'and', 'lovable', 'you', 'want', 'to', 'smack', 'him.', 'nothing', 'about', 'this', 'movie', 'rings', 'true.', 'and', \"it's\", 'boring', 'to', 'boot.', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['this', 'movie', 'is', 'so', 'bad', \"it's\", 'almost', 'good.', 'bad', 'story,', 'bad', 'acting,', 'bad', 'music,', 'you', 'name', 'it.', 'o.k.,', 'who', 'are', 'the', 'jokers', 'that', 'gave', 'this', 'flick', 'a', '<unk>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['agreeable', '<unk>', 'own', '<unk>', 'nonsense', 'with', 'a', 'sprightly', 'performance', 'from', 'cushing,', 'some', 'amusing', 'rubber', 'monsters,', 'colourful', 'jungle', 'sets,', '&', 'the', '<unk>', 'appearance', 'of', 'caroline', 'munro', 'in', 'animal', '<unk>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Negative\n",
            "['if', 'you', 'are', 'french', '<unk>', 'then', 'you', 'find', 'this', 'movie', 'extremely', 'funny.', \"it's\", 'good,', 'just', 'good!', 'can', 'though', 'imagine', 'that', 'subtitles', 'or', 'translations', \"don't\", 'mean', 'much', 'in', 'english.', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['i', \"don't\", 'believe', 'it...', 'luc', '<unk>', 'is', 'not', 'only', 'a', 'genius', '<unk>', 'has', 'always', 'been', 'one...', 'this', 'film', 'is', 'for', 'everyone', 'who', 'likes', 'real', 'good', 'deep', '<unk>', 'perfect!', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Negative\n",
            "['great', 'cast,', 'great', 'acting,', 'great', 'music.', 'each', 'character', 'in', 'this', 'movie', 'had', 'their', 'own', 'stories', 'and', 'personalities', 'and', \"it's\", '<unk>', 'a', 'great', 'movie', 'not', 'to', 'be', 'missed.', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['anyone', 'who', 'gives', 'this', 'movie', 'less', 'than', '8', 'needs', 'to', 'step', 'outside', '&', 'puff', 'a', 'couple.', 'great', 'story.<br', '/><br', '<unk>', 'is', 'for', 'people', 'who', \"can't\", 'handle', 'drugs.', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['i', 'really', 'enjoyed', 'this', 'movie...', 'in', 'my', 'dvd', 'collection', 'of', 'baseball', 'movies...', 'reminded', 'me', 'how', 'great', 'the', 'sport', 'truly', 'is...', 'whether', \"it's\", 'here', 'in', 'america', 'or', 'japan.', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['this', 'movie', 'was', 'so', 'incredibly', 'boring,', 'michael', 'j.', 'fox', \"could've\", 'done', 'so', 'much', 'better.', 'sorry,', 'but', \"it's\", 'true', 'for', 'all', 'you', 'people', 'who', 'liked', 'the', 'movie', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['subject', '<unk>', '<unk>', 'quantum', 'physics', 'and', 'stephen', '<unk>', '/><br', '<unk>', 'phillip', '<unk>', '/><br', '/>have', 'i', 'died', 'and', 'gone', 'to', '<unk>', '<br', '/><br', '/>you', 'will', 'be', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['john', '<unk>', '<unk>', 'is', 'one', 'of', 'the', 'funniest', 'one-man', 'shows', \"i've\", 'ever', 'seen!', 'i', 'recommend', 'it', 'to', 'anyone!', 'well,', 'anyone', 'with', 'a', 'good', 'sense', 'of', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "[\"you've\", 'got', 'to', 'be', 'kidding.', 'this', 'movie', 'sucked', 'for', 'the', 'sci-fi', 'fans.', 'i', 'would', 'only', 'recommend', 'watching', 'this', 'only', 'if', 'you', 'think', 'armageddon', 'was', 'good.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Positive\n",
            "['i', 'caught', 'this', 'film', 'late', 'at', 'night', 'on', 'hbo.', 'talk', 'about', 'wooden', 'acting,', 'unbelievable', 'plot,', 'et', 'al.', 'very', 'little', 'going', 'in', 'its', 'favor.', 'skip', 'it.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['the', 'plot', 'was', 'really', 'weak', 'and', 'confused.', 'this', 'is', 'a', 'true', 'oprah', 'flick.', '(in', '<unk>', 'world,', 'all', 'men', 'are', 'evil', 'and', 'all', 'women', 'are', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['<unk>', 'incomprehensible', 'script', '(when', 'it', \"shouldn't\", 'have', '<unk>', 'dependent', 'on', 'a', 'rather', 'flaky', '<unk>', '/><br', '/>the', 'animation,', 'however,', 'show', 'real', 'talent.<br', '/><br', '/>quite', 'visually', 'impressive.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['<unk>', 'classic', '<unk>', 'one', 'of', 'his', 'best', 'and', 'most', 'shocking', 'films!', 'divine', 'is', 'the', 'most', 'filthy', 'person', 'ever!', 'mink', 'stole', 'also', 'delivers', 'a', 'superb', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "[\"don't\", 'waste', 'your', 'time', 'and', 'money', 'on', 'it.', \"it's\", 'not', 'quite', 'as', 'bad', 'as', '<unk>', 'by', 'the', 'same', 'director', 'but', \"that's\", 'not', 'saying', 'much.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['great', 'story,', 'great', 'music.', 'a', 'heartwarming', 'love', 'story', \"that's\", 'beautiful', 'to', 'watch', 'and', 'delightful', 'to', 'listen', 'to.', 'too', 'bad', 'there', 'is', 'no', 'soundtrack', 'cd.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['this', 'is', 'the', 'greatest', 'movie', 'ever.', 'if', 'you', 'have', 'written', 'it', 'off', 'with', 'out', 'ever', 'seeing', 'it.', 'you', 'must', 'give', 'it', 'a', 'second', 'try.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['the', 'acrobatics', 'mixed', 'with', 'haunting', 'music,', 'make', 'one', 'spectacular', 'show.', 'the', 'costumes', 'are', 'vibrant', 'and', 'the', 'performances', 'will', 'just', '<unk>', 'your', 'mind!', 'simply', 'amazing!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['very', 'intelligent', 'language', 'usage', 'of', '<unk>', 'which', 'you', '<unk>', 'miss!', 'in', 'one', 'word:', '<unk>', '<unk>', 'wicked,', 'so', 'keep', 'it', 'real', 'and', 'pass', 'it', 'on!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['a', 'great', 'film', 'in', 'its', 'genre,', 'the', 'direction,', 'acting,', 'most', 'especially', 'the', 'casting', 'of', 'the', 'film', 'makes', 'it', 'even', 'more', 'powerful.', 'a', 'must', 'see.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['as', 'a', 'big', 'fan', 'of', 'tiny', '<unk>', 'adventures,', 'i', 'loved', 'this', 'movie!!!', 'it', 'was', 'so', '<unk>', 'it', 'really', 'captured', 'how', 'cartoons', 'spent', 'their', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['this', 'movie', 'is', 'terrible.', \"it's\", 'about', 'some', 'no', 'brain', '<unk>', 'dude', 'that', 'inherits', 'some', 'company.', 'does', 'carrot', 'top', 'have', 'no', '<unk>', '/><br', '/>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['this', 'is', 'quite', 'possibly', 'the', 'worst', 'sequel', 'ever', 'made.', 'the', 'script', 'is', 'unfunny', 'and', 'the', 'acting', 'stinks.', 'the', 'exact', 'opposite', 'of', 'the', 'original.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['this', 'is', 'a', 'terrible', 'movie,', \"don't\", 'waste', 'your', 'money', 'on', 'it.', \"don't\", 'even', 'watch', 'it', 'for', 'free.', \"that's\", 'all', 'i', 'have', 'to', 'say.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['if', \"you've\", 'ever', 'had', 'a', 'mad', 'week-end', 'out', 'with', 'your', 'mates', 'then', \"you'll\", 'appreciate', 'this', 'film.', 'excellent', 'fun', 'and', 'a', 'laugh', 'a', 'minute.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['ten', 'minutes', 'of', 'people', 'spewing', 'gallons', 'of', 'pink', 'vomit.', 'recurring', 'scenes', 'of', 'enormous', 'piles', 'of', 'dog', 'excrement', '-', 'need', 'one', 'say', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['brilliant.', 'ranks', 'along', 'with', 'citizen', 'kane,', 'the', 'matrix', 'and', '<unk>', 'must', 'see,', 'at', 'least', 'for', '<unk>', 'in', 'her', 'early', 'days.', 'watch', 'it.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['widow', 'hires', 'a', 'psychopath', 'as', 'a', '<unk>', 'sloppy', 'film', 'noir', 'thriller', 'which', \"doesn't\", 'make', 'much', 'of', 'its', 'tension', 'promising', '<unk>', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Positive\n",
            "['for', 'pure', 'gothic', 'vampire', 'cheese', 'nothing', 'can', 'compare', 'to', 'the', '<unk>', 'films.', 'i', 'highly', 'recommend', 'each', 'and', 'every', 'one', 'of', 'them.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['one', 'of', 'the', 'funniest', 'movies', 'made', 'in', 'recent', 'years.', 'good', 'characterization,', 'plot', 'and', 'exceptional', 'chemistry', 'make', 'this', 'one', 'a', 'classic', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['a', 'touching', 'movie.', 'it', 'is', 'full', 'of', 'emotions', 'and', 'wonderful', 'acting.', 'i', 'could', 'have', 'sat', 'through', 'it', 'a', 'second', 'time.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['if', 'you', 'like', 'pauly', '<unk>', \"you'll\", 'love', 'son', 'in', 'law.', 'if', 'you', 'hate', 'pauly', '<unk>', 'then,', '<unk>', 'liked', 'it!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['without', 'a', 'doubt,', 'one', 'of', 'tobe', '<unk>', 'best!', 'epic', '<unk>', 'great', 'special', 'effects,', 'and', 'the', '<unk>', '<unk>', 'me', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['this', 'is', 'a', 'good', 'film.', 'this', 'is', 'very', 'funny.', 'yet', 'after', 'this', 'film', 'there', 'were', 'no', 'good', 'ernest', 'films!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['hated', 'it', 'with', 'all', 'my', 'being.', 'worst', 'movie', 'ever.', '<unk>', '<unk>', 'help', 'me.', 'it', 'was', 'that', '<unk>', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['absolutely', 'fantastic!', 'whatever', 'i', 'say', \"wouldn't\", 'do', 'this', 'underrated', 'movie', 'the', 'justice', 'it', 'deserves.', 'watch', 'it', 'now!', 'fantastic!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['add', 'this', 'little', 'gem', 'to', 'your', 'list', 'of', 'holiday', '<unk>', 'it', 'is<br', '/><br', '<unk>', 'funny,', 'and', 'endearing', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['just', 'love', 'the', 'interplay', 'between', 'two', 'great', 'characters', 'of', 'stage', '&', 'screen', '-', 'veidt', '&', 'barrymore', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['a', 'mesmerizing', 'film', 'that', 'certainly', 'keeps', 'your', '<unk>', 'ben', 'daniels', 'is', 'fascinating', '(and', '<unk>', 'to', 'watch.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['this', 'is', 'a', 'great', 'movie.', 'too', 'bad', 'it', 'is', 'not', 'available', 'on', 'home', 'video.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['brilliant', 'and', 'moving', 'performances', 'by', 'tom', '<unk>', 'and', 'peter', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Positive\n",
            "Prediction : Positive\n",
            "['what', 'a', 'script,', 'what', 'a', 'story,', 'what', 'a', 'mess!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Positive\n",
            "['i', 'hope', 'this', 'group', 'of', 'film-makers', 'never', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['more', 'suspenseful,', 'more', 'subtle,', 'much,', 'much', 'more', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Positive\n",
            "['read', 'the', 'book,', 'forget', 'the', 'movie!', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n",
            "['primary', '<unk>', '<unk>', 'interpretation.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Answer : Negative\n",
            "Prediction : Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF5iyjA0xmx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델은 pt 파일 형태로 저장됩니다\n",
        "torch.save(model.state_dict(), '/gdrive/My Drive/IMDB_RNN.pt')\n",
        "\n",
        "# 모델을 불러오기 위해 지워줍니다\n",
        "del model\n",
        "\n",
        "model = MLP(784).to(device)\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/IMDB_RNN.pt'))\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}